

## Project Overview:
# Summary:
You will be tasked with creating a location-based analytics web application which will prompt a user to input a location via ZIP code or an interactive pinpointing component. The application will then respond with insights regarding housing prices, crime rates, local weather patterns, and infrastructure quality based on machine learning model predictions your team will generate using relevant datasets. This project will introduce you to core concepts in basic machine learning and data visualization, as well as full-stack web development.
The backend will leverage data and machine learning models to make predictions. The frontend will present this information in a user-friendly, interactive dashboard.
This project is a great way to learn how to combine data science, machine learning, and some web development to create an impactful and informative tool regarding living conditions.
# Basic Terminology to know:
Machine Learning: Machine learning (ML) is a branch of artificial intelligence focused on enabling computers and machines to imitate the way that humans learn, to perform tasks autonomously, and to improve their performance and accuracy through experience and exposure to more data. There are supervised, unsupervised, and semi-supervised learning models, but for the purposes of this project we will be focusing on supervised learning: Which develops a predictive model based on both input and output data. Examples of supervised machine learning models would be Linear Regression, Decision Tree, K Nearest Neighbors, Random Forest, and Naive Bayes.
Frontend: This refers to the development of the graphical user interface of a website, through the use of HTML, CSS, and JavaScript, so that users can view and interact with that website.
Possible technologies involve using pure HTML, CSS and JavaScript or frameworks such as React.js (recommended), Angular.js, Vue.js, Svelte, etc. For this project the front-end will be a smaller aspect but still important for effectively displaying model predictions and results to the user based off of their inputted data. This is a great opportunity to show unique and engaging data visualizations if time permits.
Backend: A critical component of a web application or website that operates behind the scenes to manage and process data, as well as handle the core logic and functionality. It is responsible for various tasks that enable the frontend (the user interface) and the server to interact and deliver a seamless user experience. Some possible frameworks to use for the backend are Flask, FastAPI, or Django. This project's backend will consist of the models making predictions that will need to be communicated to the user via the dashboard.
# Models:
Housing Model: he best-fit model for predicting housing prices based on the given dataset is a Gradient Boosting model, such as XGBoost, due to its ability to handle the complex and nonlinear relationships inherent in real estate data. The dataset includes a mix of numerical features (like house size, lot size, number of beds and baths) and categorical variables (such as city, state, and ZIP code), which Gradient Boosting models manage effectively through built-in handling of missing data, feature importance calculation, and robust ensemble learning techniques. Unlike simpler models such as linear regression, which assume linearity and may underperform when relationships between features are intricate, Gradient Boosting models can capture subtle interactions and patterns that significantly influence housing prices. Additionally, they offer scalability, tunability, and strong predictive performance, making them ideal for this supervised regression task where accurate price estimation is critical for providing meaningful insights to users through the web application.
Data Set: https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset

Crime Model: I believe the most that will be most effective on predicting crime rates based off my dataset is a RandomForest Regression model as it is able be work well with structured data as is this dataset where the relationships between variables can sometimes be complex and interdependent. Also having the nature of random forest ensures that the handling of non-linear relationships is done effectively while also mitigating overfitting coming from just a single decision tree. What makes RandomForest special is that it there is a level of robustness to noise and outliers since the idea of this model is aggregating results from multiple decision trees, reducing the impact of noisy data with causes a skew in data. Lastly, this model is fairly simple in use and tuning as it has relatively few hyperparameters compared to other methods which saves time and increases computational efficiency. 
