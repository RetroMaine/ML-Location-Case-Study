{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954c83bc-94a1-454b-93b3-224a3af89d53",
   "metadata": {},
   "source": [
    "# 1. Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87d5fdca-f57a-46a1-acb7-e565a9177cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Types:\n",
      "violent_crime    float64\n",
      "murder           float64\n",
      "rape             float64\n",
      "robbery          float64\n",
      "population         int64\n",
      "dtype: object\n",
      "\n",
      "Cleaned DataFrame Shape: (214, 12)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#########################################################################################################\n",
    "df = pd.read_csv(\"archive-1/crime_60_100.csv\")\n",
    "\n",
    "numeric_cols = ['violent_crime', 'murder', 'rape', 'robbery', 'population'] \n",
    "\n",
    "for col in numeric_cols:\n",
    "    # if col in numeric_cols:\n",
    "        df[col] = df[col].astype(str).str.replace(',', '')  \n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  \n",
    "\n",
    "df_clean = df.dropna(subset=numeric_cols)\n",
    "\n",
    "# verify cleaned data\n",
    "print(\"Cleaned Data Types:\")\n",
    "print(df_clean[numeric_cols].dtypes)\n",
    "print(\"\\nCleaned DataFrame Shape:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298c598-9950-43b6-a42d-4bf95801cb42",
   "metadata": {},
   "source": [
    "# 2. Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "303c1b6b-dd2c-4496-bb54-0fea8ef3003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per capita crime rates \n",
    "features = df_clean[['population', 'states']]\n",
    "targets = df_clean[['violent_crime', 'murder', 'rape', 'robbery']].div(df_clean['population'], axis=0)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     features, targets, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('state_encoder', OneHotEncoder(handle_unknown='ignore'), ['states'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_processed = preprocessor.fit_transform(features) \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, targets.values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.toarray() if hasattr(X_train, 'toarray') else X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test.toarray() if hasattr(X_test, 'toarray') else X_test)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "y_test_tensor = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9522d-13f5-4ec2-8633-efa6d1a11131",
   "metadata": {},
   "source": [
    "# 3. PyTorch Model definitionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89765277-5278-4e84-a675-92d5c07b1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrimePredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CrimePredictor, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 64), # linear @params\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(32, 4) # we want 4 output features\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1a592-acbf-4d61-ab3b-5528cfd03824",
   "metadata": {},
   "source": [
    "# 4. Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6422d25-3c4a-4d83-b69c-1114c8e12068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input size from preprocessed data\n",
    "# input_size = X_train_tensor.shape[1]\n",
    "# model = CrimePredictor(input_size)\n",
    "model = CrimePredictor(input_size=X_train_tensor.shape[1]) \n",
    "\n",
    "criterion = nn.L1Loss()  # MAE loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# create dataloader\n",
    "class CrimeDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "        \n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad8ab6-3961-48e5-816c-e34edf910156",
   "metadata": {},
   "source": [
    "# 5. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b795eb8-51a9-43fc-ab86-9a1d29fb08e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "Train MAE: 2.5104 | Test MAE: 1.6287\n",
      "Epoch 40/200\n",
      "Train MAE: 1.4737 | Test MAE: 1.6058\n",
      "Epoch 60/200\n",
      "Train MAE: 0.9660 | Test MAE: 0.6373\n",
      "Epoch 80/200\n",
      "Train MAE: 0.3106 | Test MAE: 0.3872\n",
      "Epoch 100/200\n",
      "Train MAE: 0.2913 | Test MAE: 0.2509\n",
      "Epoch 120/200\n",
      "Train MAE: 0.1401 | Test MAE: 0.0517\n",
      "Epoch 140/200\n",
      "Train MAE: 0.0419 | Test MAE: 0.0448\n",
      "Epoch 160/200\n",
      "Train MAE: 0.0500 | Test MAE: 0.0066\n",
      "Epoch 180/200\n",
      "Train MAE: 0.0658 | Test MAE: 0.0050\n",
      "Epoch 200/200\n",
      "Train MAE: 0.1299 | Test MAE: 0.0087\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor) \n",
    "    train_loss = train_loss / len(train_loader.dataset) \n",
    "\n",
    "    # early stop check\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')  \n",
    "        print(f'Train MAE: {train_loss:.4f} | Test MAE: {test_loss:.4f}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6596bf5-a008-4a2d-8ac2-f5d44c996f16",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26688cfc-3eeb-4b60-a4b9-c661100a87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Load best model\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     train_pred = model(X_train_tensor).numpy()\n",
    "#     test_pred = model(X_test_tensor).numpy()\n",
    "\n",
    "# print(f\"\\nFinal Train MAE: {mean_absolute_error(y_train, train_pred):.4f}\")\n",
    "# print(f\"Final Test MAE: {mean_absolute_error(y_test, test_pred):.4f}\")\n",
    "\n",
    "\n",
    "# # # use for predicting \n",
    "# # def predict_crime_rates(population: int, state: str):\n",
    "# #     input_df = pd.DataFrame([[population, state]], columns=['population', 'states'])\n",
    "# #     processed = preprocessor.transform(input_df)\n",
    "# #     input_tensor = torch.FloatTensor(processed)\n",
    "# #     with torch.no_grad():\n",
    "# #         prediction = model(input_tensor).numpy()[0]\n",
    "# #     return {\n",
    "# #         'violent_crime_rate': prediction[0],\n",
    "# #         'murder_rate': prediction[1],\n",
    "# #         'rape_rate': prediction[2],\n",
    "# #         'robbery_rate': prediction[3]\n",
    "# #     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098fad5c-a416-4f88-bc14-513bd403d595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
